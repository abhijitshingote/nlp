{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904bf329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%config Completer.use_jedi = False\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "# %config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13e4dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 189)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 189, 20)           155620    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 187, 16)           976       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 62, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 60, 32)            1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 18, 64)            6208      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 164,437\n",
      "Trainable params: 164,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "131/131 [==============================] - 2s 8ms/step - loss: 0.3597 - accuracy: 0.8626 - val_loss: 0.1858 - val_accuracy: 0.9210\n",
      "Epoch 2/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0914 - accuracy: 0.9727 - val_loss: 0.0667 - val_accuracy: 0.9756\n",
      "Epoch 3/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9849 - val_loss: 0.0660 - val_accuracy: 0.9785\n",
      "Epoch 4/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.0462 - val_accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0419 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0369 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0462 - val_accuracy: 0.9871\n",
      "Epoch 8/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0751 - val_accuracy: 0.9864\n",
      "Epoch 9/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0567 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0802 - val_accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('spam.csv',error_bad_lines=False,encoding= 'Windows-1252')\n",
    "X=df['v2']\n",
    "y=df['v1'].apply(lambda x:0 if x=='spam' else 1)\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.25)\n",
    "\n",
    "num_words=None\n",
    "embedding_length=20\n",
    "tok=Tokenizer(num_words=num_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "X_train=tok.texts_to_sequences(X_train)\n",
    "X_test=tok.texts_to_sequences(X_test)\n",
    "X_train=pad_sequences(X_train)\n",
    "X_test=pad_sequences(X_test,maxlen=X_train.shape[1])\n",
    "y_train=y_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "\n",
    "maxsequencelength=X_train.shape[1]\n",
    "input_dim=num_words if num_words else (max(tok.word_index.values())+1)\n",
    "\n",
    "inputlayer=tf.keras.layers.Input(shape=[maxsequencelength,])\n",
    "x=tf.keras.layers.Embedding(input_dim=input_dim,output_dim=embedding_length,input_length=maxsequencelength)(inputlayer)\n",
    "x=tf.keras.layers.Conv1D(16,3,activation='relu')(x)\n",
    "x=tf.keras.layers.MaxPooling1D(3)(x)\n",
    "x=tf.keras.layers.Conv1D(32,3,activation='relu')(x)\n",
    "x=tf.keras.layers.MaxPooling1D(3)(x)\n",
    "x=tf.keras.layers.Conv1D(64,3,activation='relu')(x)\n",
    "x=tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "x=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "mymodel=tf.keras.Model(inputs=inputlayer,outputs=x)\n",
    "mymodel.summary()\n",
    "\n",
    "mymodel.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "r = mymodel.fit(x=X_train, y=y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cb7b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=list(df['v2'].values)\n",
    "\n",
    "def get_augmented_text(text):\n",
    "    newtextlist=[]\n",
    "    for eachtext in text:\n",
    "        char_to_replace=random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "        replace_char_with=random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "        newtext=eachtext.replace(char_to_replace,replace_char_with)\n",
    "        newtextlist.append([[eachtext,newtext],0])\n",
    "    return newtextlist\n",
    "\n",
    "def get_neg_samples(text):\n",
    "    negsamplelist=[]\n",
    "    for _ in range(5):\n",
    "        for i,eachtext in enumerate(text):\n",
    "            negsample=random.choice(text)\n",
    "            while eachtext == negsample:\n",
    "                negsample=random.choice(text)\n",
    "            negsamplelist.append([[eachtext,negsample],1])\n",
    "    return negsamplelist\n",
    "\n",
    "augmentedtext=get_augmented_text(text)\n",
    "negsamplestext=get_neg_samples(text)\n",
    "X1=[]\n",
    "X2=[]\n",
    "y=[]\n",
    "alltrainingsamples=augmentedtext+negsamplestext\n",
    "random.shuffle(alltrainingsamples)\n",
    "for sample in alltrainingsamples:\n",
    "    X1.append(sample[0][0])\n",
    "    X2.append(sample[0][1])\n",
    "    y.append(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e60ba5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "836/836 [==============================] - 11s 12ms/step - loss: 0.4534 - auc_4: 0.4983 - accuracy: 0.8347 - val_loss: 0.4607 - val_auc_4: 0.4880 - val_accuracy: 0.8279\n",
      "Epoch 2/10\n",
      "836/836 [==============================] - 10s 12ms/step - loss: 0.4519 - auc_4: 0.5010 - accuracy: 0.8347 - val_loss: 0.4608 - val_auc_4: 0.5076 - val_accuracy: 0.8279\n",
      "Epoch 3/10\n",
      "836/836 [==============================] - 10s 12ms/step - loss: 0.4522 - auc_4: 0.5100 - accuracy: 0.8347 - val_loss: 0.4644 - val_auc_4: 0.4856 - val_accuracy: 0.8279\n",
      "Epoch 4/10\n",
      "836/836 [==============================] - 10s 12ms/step - loss: 0.4504 - auc_4: 0.5239 - accuracy: 0.8347 - val_loss: 0.4656 - val_auc_4: 0.4678 - val_accuracy: 0.8279\n",
      "Epoch 5/10\n",
      "836/836 [==============================] - 10s 12ms/step - loss: 0.4518 - auc_4: 0.5189 - accuracy: 0.8347 - val_loss: 0.4745 - val_auc_4: 0.4930 - val_accuracy: 0.8279\n",
      "Epoch 6/10\n",
      "836/836 [==============================] - 11s 13ms/step - loss: 0.4499 - auc_4: 0.5333 - accuracy: 0.8347 - val_loss: 0.4641 - val_auc_4: 0.4769 - val_accuracy: 0.8279\n",
      "Epoch 7/10\n",
      "836/836 [==============================] - 10s 12ms/step - loss: 0.4503 - auc_4: 0.5336 - accuracy: 0.8347 - val_loss: 0.4687 - val_auc_4: 0.4642 - val_accuracy: 0.8279\n",
      "Epoch 8/10\n",
      "836/836 [==============================] - 10s 12ms/step - loss: 0.4499 - auc_4: 0.5407 - accuracy: 0.8347 - val_loss: 0.4670 - val_auc_4: 0.4626 - val_accuracy: 0.8279\n",
      "Epoch 9/10\n",
      "836/836 [==============================] - 12s 14ms/step - loss: 0.4484 - auc_4: 0.5451 - accuracy: 0.8347 - val_loss: 0.4725 - val_auc_4: 0.4738 - val_accuracy: 0.8279\n",
      "Epoch 10/10\n",
      "836/836 [==============================] - 13s 15ms/step - loss: 0.4494 - auc_4: 0.5423 - accuracy: 0.8347 - val_loss: 0.4765 - val_auc_4: 0.4661 - val_accuracy: 0.8279\n"
     ]
    }
   ],
   "source": [
    "embedding_length=100\n",
    "maxsequencelength=100\n",
    "\n",
    "tok=tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "\n",
    "tok.fit_on_texts(X1 + X2)\n",
    "X1=tok.texts_to_sequences(X1)\n",
    "X2=tok.texts_to_sequences(X2)\n",
    "X1=tf.keras.preprocessing.sequence.pad_sequences(X1,maxlen=maxsequencelength)\n",
    "X2=tf.keras.preprocessing.sequence.pad_sequences(X2,maxlen=maxsequencelength)\n",
    "input_dim=max(tok.word_index.values())+1\n",
    "\n",
    "def get_feature_map(inputlayer):\n",
    "    x=tf.keras.layers.Embedding(input_dim=input_dim,output_dim=embedding_length,input_length=maxsequencelength)(inputlayer)\n",
    "    x=tf.keras.layers.Conv1D(16,5,activation='relu')(x)\n",
    "    x=tf.keras.layers.MaxPooling1D(3)(x)\n",
    "    x=tf.keras.layers.Conv1D(32,3,activation='relu')(x)\n",
    "    x=tf.keras.layers.MaxPooling1D(3)(x)\n",
    "    x=tf.keras.layers.Conv1D(64,3,activation='relu')(x)\n",
    "    featuremap=tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "    return featuremap\n",
    "\n",
    "\n",
    "inputlayer1=tf.keras.layers.Input(shape=[maxsequencelength,])\n",
    "featuremap1=get_feature_map(inputlayer1)\n",
    "inputlayer2=tf.keras.layers.Input(shape=[maxsequencelength,])\n",
    "featuremap2=get_feature_map(inputlayer2)\n",
    "difference=featuremap1 - featuremap2\n",
    "output=tf.keras.layers.Dense(1,activation='sigmoid')(difference)\n",
    "mymodel=tf.keras.Model(inputs=[inputlayer1,inputlayer2],outputs=output)\n",
    "\n",
    "mymodel.compile(loss='binary_crossentropy',metrics=[tf.keras.metrics.AUC(),'accuracy'])\n",
    "r = mymodel.fit([X1,X2], np.array(y), epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1897105",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictme=text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f1e6b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19,\n",
       "  3,\n",
       "  1,\n",
       "  12,\n",
       "  7,\n",
       "  4,\n",
       "  6,\n",
       "  10,\n",
       "  1,\n",
       "  36,\n",
       "  12,\n",
       "  9,\n",
       "  3,\n",
       "  7,\n",
       "  19,\n",
       "  1,\n",
       "  20,\n",
       "  3,\n",
       "  6,\n",
       "  7,\n",
       "  4,\n",
       "  26,\n",
       "  1,\n",
       "  17,\n",
       "  9,\n",
       "  5,\n",
       "  45,\n",
       "  16,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  5,\n",
       "  24,\n",
       "  5,\n",
       "  6,\n",
       "  10,\n",
       "  5,\n",
       "  22,\n",
       "  10,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  7,\n",
       "  10,\n",
       "  16,\n",
       "  1,\n",
       "  6,\n",
       "  7,\n",
       "  1,\n",
       "  22,\n",
       "  12,\n",
       "  19,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  19,\n",
       "  9,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  18,\n",
       "  3,\n",
       "  9,\n",
       "  10,\n",
       "  13,\n",
       "  1,\n",
       "  10,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  22,\n",
       "  12,\n",
       "  21,\n",
       "  21,\n",
       "  2,\n",
       "  4,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  17,\n",
       "  6,\n",
       "  7,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  11,\n",
       "  2,\n",
       "  9,\n",
       "  2,\n",
       "  1,\n",
       "  19,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  15,\n",
       "  3,\n",
       "  9,\n",
       "  2,\n",
       "  1,\n",
       "  18,\n",
       "  5,\n",
       "  4,\n",
       "  14,\n",
       "  14,\n",
       "  14]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.texts_to_sequences([predictme])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1225f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  3,  7, 19,  1, 20,  3,  6,  7,  4, 26,  1, 17,  9,  5, 45,\n",
       "        16, 14, 14,  1,  5, 24,  5,  6, 10,  5, 22, 10,  2,  1,  3,  7,\n",
       "        10, 16,  1,  6,  7,  1, 22, 12, 19,  6,  8,  1,  7,  1, 19,  9,\n",
       "         2,  5,  4,  1, 18,  3,  9, 10, 13,  1, 10,  5,  1,  2,  1, 22,\n",
       "        12, 21, 21,  2,  4, 14, 14, 14,  1, 17,  6,  7,  2,  1,  4, 11,\n",
       "         2,  9,  2,  1, 19,  3,  4,  1,  5, 15,  3,  9,  2,  1, 18,  5,\n",
       "         4, 14, 14, 14]], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences([predictme]),maxlen=maxsequencelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47d18077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5689533950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.89613146]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.predict(\n",
    "   [ tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences([predictme]),maxlen=maxsequencelength),\n",
    "    tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences([predictme]),maxlen=maxsequencelength)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53d241c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 100, 100)     9200        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 100, 100)     9200        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 98, 16)       4816        embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 98, 16)       4816        embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 32, 16)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 32, 16)       0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 30, 32)       1568        max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 30, 32)       1568        max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 10, 32)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 10, 32)       0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 8, 64)        6208        max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 8, 64)        6208        max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 64)           0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 64)           0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_5 (TFOpLambda) (None, 64)           0           global_max_pooling1d_11[0][0]    \n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            65          tf.math.subtract_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 43,649\n",
      "Trainable params: 43,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3872288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_12\n",
      "1 input_13\n",
      "2 embedding_11\n",
      "3 embedding_12\n",
      "4 conv1d_33\n",
      "5 conv1d_36\n",
      "6 max_pooling1d_22\n",
      "7 max_pooling1d_24\n",
      "8 conv1d_34\n",
      "9 conv1d_37\n",
      "10 max_pooling1d_23\n",
      "11 max_pooling1d_25\n",
      "12 conv1d_35\n",
      "13 conv1d_38\n",
      "14 global_max_pooling1d_11\n",
      "15 global_max_pooling1d_12\n",
      "16 tf.math.subtract_5\n",
      "17 dense_6\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(mymodel.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e248962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynewmodel=tf.keras.Model(inputs=mymodel.input,outputs=mymodel.layers[-4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c91b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5669ed6048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.18673281,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , 16.33448   ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  2.855888  ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynewmodel.predict(\n",
    " [ tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences([predictme]),maxlen=maxsequencelength),\n",
    "    tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences([predictme]),maxlen=maxsequencelength)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a6937af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynewmodel2=tf.keras.Model(inputs=mymodel.input,outputs=mymodel.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11269b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2148689 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.5052018 , 0.        ,\n",
       "        0.        , 0.        , 1.3258188 , 0.        , 0.        ,\n",
       "        0.20750208, 0.        , 0.        , 0.35692635, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.4527096 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16306864,\n",
       "        0.        , 0.        , 0.        , 0.        , 2.132071  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.743058  , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7688881 , 0.        , 0.        , 1.8490735 ,\n",
       "        0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynewmodel2.predict(\n",
    " [ tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences([predictme]),maxlen=maxsequencelength),\n",
    "    tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences([predictme]),maxlen=maxsequencelength)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c5955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
